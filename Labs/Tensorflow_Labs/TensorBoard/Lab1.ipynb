{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13518e9-7903-4393-ab58-6027b10c5936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565b05a0-4a69-44f7-9370-e2f19f94f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c238774-e8f7-46b2-b8d9-3ff7d5da7a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 20:56:36.558911: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-04 20:56:36.558967: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-04 20:56:36.610119: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-04 20:56:36.740765: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 20:56:37.915095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabled dumping callback in thread MainThread (dump root: ./logs/, tensor debug mode: FULL_HEALTH)\n",
      "TensorFlow version:  2.15.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.debugging.experimental.enable_dump_debug_info('./logs/',\n",
    "                                                 tensor_debug_mode=\"FULL_HEALTH\", \n",
    "                                                 circular_buffer_size=-1)\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6285810b-541b-4fba-a4cf-674824c9bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1000\n",
    "# 80% of the data is for training.\n",
    "train_pct = 0.8\n",
    "\n",
    "train_size = int(data_size * train_pct)\n",
    "\n",
    "# Create some input data between -1 and 1 and randomize it.\n",
    "x = np.linspace(-1, 1, data_size)\n",
    "np.random.shuffle(x)\n",
    "\n",
    "# Generate the output data.\n",
    "# y = 0.5x + 2 + noise\n",
    "y = 0.5 * x + 2 + np.random.normal(0, 0.05, (data_size, ))\n",
    "\n",
    "# Split into test and train pairs.\n",
    "x_train, y_train = x[:train_size], y[:train_size]\n",
    "x_test, y_test = x[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0758b203-9ef0-4f93-92ca-d8c938f2dc35",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Failed to read source code from path: /tmp/ipykernel_48201/2447297959.py. Reason: Source path neither exists nor can be loaded as a .par file: /tmp/ipykernel_48201/2447297959.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 20:56:43.476305: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ... With default parameters, this takes less than 10 seconds.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 4.0232 - val_loss: 0.0409\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0452 - val_loss: 0.0144\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0131 - val_loss: 0.0041\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Average test loss:  0.2062966294353828\n"
     ]
    }
   ],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(16, input_dim=1),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='mse', # keras.losses.mean_squared_error\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.2),\n",
    ")\n",
    "\n",
    "print(\"Training ... With default parameters, this takes less than 10 seconds.\")\n",
    "training_history = model.fit(\n",
    "    x_train, # input\n",
    "    y_train, # output\n",
    "    batch_size=train_size,\n",
    "    verbose=1, # Suppress chatty output; use Tensorboard instead\n",
    "    epochs=20,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[tensorboard_callback],\n",
    ")\n",
    "\n",
    "print(\"Average test loss: \", np.average(training_history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fea27459-f3cd-4673-8fbf-de89ccc39df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5d6e3c3-e9e0-4452-bf1b-ce64bbef62c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4d7c71a30579e72b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4d7c71a30579e72b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26237f7e-91fc-41aa-9d8a-134bc291392c",
   "metadata": {},
   "source": [
    "A brief overview of the visualizations created in this example and the dashboards (tabs in top navigation bar) where they can be found:\n",
    "\n",
    "* Scalars show how the loss and metrics change with every epoch. You can use them to also track training speed, learning rate, and other scalar values. Scalars can be found in the Time Series or Scalars dashboards.\n",
    "* Graphs help you visualize your model. In this case, the Keras graph of layers is shown which can help you ensure it is built correctly. Graphs can be found in the Graphs dashboard.\n",
    "* Histograms and Distributions show the distribution of a Tensor over time. This can be useful to visualize weights and biases and verify that they are changing in an expected way. Histograms can be found in the Time Series or Histograms dashboards. Distributions can be found in the Distributions dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ab25fc-57f9-4b65-a85e-e6c71cca1bdd",
   "metadata": {},
   "source": [
    "Breakdown of the Debugger Interface\n",
    "The Debugger Dashboard on the Tensorboard consists of five main components:\n",
    "\n",
    "* __Alerts:__ This top-left section contains a list of alert events detected by the debugger in the debug data from the instrumented TensorFlow program. Each alert indicates a certain anomaly that warrants attention. In our case, this section highlights 499 NaN/∞ events with a salient pink-red color. This confirms our suspicion that the model fails to learn because of the presence of NaNs and/or infinities in its internal tensor values.\n",
    "* __Python Execution Timeline:__ This is the upper half of the top-middle section. It presents the full history of the eager execution of ops and graphs. Each box of the timeline is marked by the initial letter of the op or graph’s name. We can navigate this timeline by using the navigation buttons and the scrollbar above the timeline.\n",
    "* __Graph Execution:__ Located at the top-right corner of the GUI, this section will be central to our debugging task. It contains a history of all the floating-type tensors computed inside graphs, i.e., the ones compiled by @tf-functions.\n",
    "* __Stack Trace:__ The bottom-right section, shows the stack trace of the creation of every single operation on the graph.\n",
    "* __Source Code:__ The bottom-left section, highlights the source code corresponding to each operation on the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c32de8-23fd-4711-89c1-8aa85097a112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
